2021-12-09 23:39:17.921021: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-12-09 23:39:17.921092: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: linuxlab008.engr.wustl.edu
2021-12-09 23:39:17.921110: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: linuxlab008.engr.wustl.edu
2021-12-09 23:39:17.921211: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.57.2
2021-12-09 23:39:17.921280: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.57.2
2021-12-09 23:39:17.921295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.57.2
2021-12-09 23:39:17.922017: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-09 23:39:25.357247: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Model: "SAR_SHIP_DETECTION"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 800, 800, 1)]     0         
_________________________________________________________________
conv2d (Conv2D)              (None, 800, 800, 6)       60        
_________________________________________________________________
batch_normalization (BatchNo (None, 800, 800, 6)       24        
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 200, 200, 6)       0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 200, 200, 6)       24        
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 200, 200, 12)      660       
_________________________________________________________________
batch_normalization_2 (Batch (None, 200, 200, 12)      48        
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 50, 50, 12)        0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 50, 50, 12)        48        
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 50, 50, 24)        2616      
_________________________________________________________________
batch_normalization_4 (Batch (None, 50, 50, 24)        96        
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 25, 25, 24)        0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 25, 25, 24)        96        
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 25, 25, 48)        10416     
_________________________________________________________________
batch_normalization_6 (Batch (None, 25, 25, 48)        192       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 13, 13, 48)        0         
_________________________________________________________________
batch_normalization_7 (Batch (None, 13, 13, 48)        192       
_________________________________________________________________
flatten (Flatten)            (None, 8112)              0         
_________________________________________________________________
dense (Dense)                (None, 1024)              8307712   
_________________________________________________________________
batch_normalization_8 (Batch (None, 1024)              4096      
_________________________________________________________________
dense_1 (Dense)              (None, 512)               524800    
_________________________________________________________________
batch_normalization_9 (Batch (None, 512)               2048      
_________________________________________________________________
dense_2 (Dense)              (None, 128)               65664     
_________________________________________________________________
batch_normalization_10 (Batc (None, 128)               512       
_________________________________________________________________
dense_3 (Dense)              (None, 64)                8256      
_________________________________________________________________
batch_normalization_11 (Batc (None, 64)                256       
_________________________________________________________________
dense_4 (Dense)              (None, 32)                2080      
_________________________________________________________________
batch_normalization_12 (Batc (None, 32)                128       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 33        
_________________________________________________________________
tf.nn.relu (TFOpLambda)      (None, 1)                 0         
=================================================================
Total params: 8,930,057
Trainable params: 8,926,177
Non-trainable params: 3,880
_________________________________________________________________
None
Epoch 1/30
loss: 38.0528 - accuracy: 0.3302
Epoch 2/30
loss: 36.1746 - accuracy: 0.3530
Epoch 3/30
loss: 34.9975 - accuracy: 0.3794
Epoch 4/30
loss: 32.4216 - accuracy: 0.3949
Epoch 5/30
loss: 28.1994 - accuracy: 0.4373
Epoch 6/30
loss: 26.9657 - accuracy: 0.4556
Epoch 7/30
loss: 26.7428 - accuracy: 0.4576
Epoch 8/30
loss: 30.2454 - accuracy: 0.4129
Epoch 9/30
loss: 26.2536 - accuracy: 0.4570
Epoch 10/30
loss: 24.0369 - accuracy: 0.4705
Epoch 11/30
loss: 22.4788 - accuracy: 0.5094
Epoch 12/30
loss: 22.3132 - accuracy: 0.5062
Epoch 13/30
loss: 22.8218 - accuracy: 0.5044
Epoch 14/30
loss: 23.0749 - accuracy: 0.4957
Epoch 15/30
loss: 24.4318 - accuracy: 0.4873
Epoch 16/30
loss: 22.8842 - accuracy: 0.5086
Epoch 17/30
loss: 22.3356 - accuracy: 0.5057
Epoch 18/30
loss: 22.2734 - accuracy: 0.5021
Epoch 19/30
loss: 23.8573 - accuracy: 0.4946
Epoch 20/30
loss: 33.2964 - accuracy: 0.4849
Epoch 21/30
loss: 22.9440 - accuracy: 0.5014
Epoch 22/30
loss: 20.0128 - accuracy: 0.5294
Epoch 23/30
loss: 22.6808 - accuracy: 0.5097
Epoch 24/30
loss: 22.0838 - accuracy: 0.5060
Epoch 25/30
loss: 24.3035 - accuracy: 0.4794
Epoch 26/30
loss: 26.0718 - accuracy: 0.4581
Epoch 27/30
loss: 22.1941 - accuracy: 0.5025
Epoch 28/30
loss: 22.0125 - accuracy: 0.5013
Epoch 29/30
loss: 22.6848 - accuracy: 0.5013
Epoch 30/30
loss: 22.4125 - accuracy: 0.5097
--------------------------------------------------------
evaluate on test set
11/11 - 3s - loss: 26.9468 - accuracy: 0.4575
Model accuracy on test: 45.75%
Model loss on test 26.94682312011719
